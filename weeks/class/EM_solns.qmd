---
title: "EM: Mixture of Normals"
author: "Becky Tang"
date: "2024-03-15"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F)
set.seed(10)
n <- 60
mus <- c(2, 5, 7)
p <- c(0.3, 0.5, 0.2)
m <- length(p)
y <- sample(1:m, n, replace = T, prob = p)
x <- c(rnorm(sum(y == 1), mus[1], 1), 
       rnorm(sum(y == 2), mus[2], 1),
       rnorm(sum(y == 3), mus[3], 1))
x <- sample(x)
```

## Load data and visualize

```{r echo = T, eval = F}
library(tidyverse)
# change the file path if needed
x <- readRDS("~/Downloads/normal_mixture_data.Rda")
data.frame(x = x) %>%
  ggplot(., aes(x= x))+
  geom_histogram(bins = 15)
```

```{r echo = F, eval = T}
library(tidyverse)
x <- readRDS("data/normal_mixture_data.Rda")
data.frame(x = x) %>%
  ggplot(., aes(x= x))+
  geom_histogram(bins = 15)
```

## E-step

We will write a function called `e.step` that will calculate $P(Y_{i} = j | x_{i}, \boldsymbol{\theta} = \boldsymbol{\theta}^{old})$ for given values `mu` and `p`. When we call this function, we will pass in $\boldsymbol{\mu}^{old}$ and $\mathbf{p}^{old}$ for `mu` and `p`.

```{r}
# x = observed data
# n = number of observations
# m = number of mixture components
# mu = m-vector of means mu
# p = m-vector of component proportions
e.step <- function(x, n, m, mu, p){
  tau_mat <- matrix(NA, nrow = n, ncol = m)
  for(i in 1:n){
    p_yij <- dnorm(x[i], mu, 1) * p
    tau_mat[i,] <- p_yij/sum(p_yij)
  }
  return(tau_mat)
}
```

## Run EM algorithm

```{r}
# set m and n
n <- length(x)
m <- 3

# number of iterations until convergence; depends on the problem!
n_sim <- 108

# initialize
mu_old <- c(0, 5, 10)
p_old <- rep(1/m, m)

# create matrices for storing iterations
mu_store <- matrix(NA, nrow = n_sim, ncol = m)
p_store <- matrix(NA, nrow = n_sim, ncol = m)
mu_store[1,] <- mu_old
p_store[1,] <- p_old

# run algorithm
for(s in 2:n_sim){
  # E-step
  tau_mat <- e.step(x, n, m, mu_old, p_old)
  
  # M-step and update in one go
  for(j in 1:m){
    mu_old[j] <- sum(x * tau_mat[,j])/sum(tau_mat[,j])
    p_old[j] <- sum(tau_mat[,j])/n
  }
  
  # just to keep track to monitor convergence
  mu_store[s,] <- mu_old
  p_store[s,] <- p_old
}
```

### Assess convergence

We will look at the last few iterations to see if the algorithm as converged. If not, we need to increase the number of simulations!

```{r}
# tail() shows last six elements of a vector/matrix
tail(mu_store)
tail(p_store)
```

It seems like we hit convergence after 106 iterations. Depending on the problem, we may need fewer or more iterations.

Our MLEs are $\hat{\boldsymbol{\mu}}_{MLE} =$ (`r mu_store[n_sim,]`) and $\hat{\mathbf{p}}_{MLE} =$ (`r p_store[n_sim,]`). How did we do?

::: {.callout-tip collapse="true"}
## Expand to see true values

The true parameter values are:

$\boldsymbol{\mu}$: (`r mus`)

$\mathbf{p}$: (`r p`)
:::
